
@article{Camargo.Gudwin_2022_SignalsKnowledgeKnowledgeActionPeirceanSemioticsGroundingCognition,
  title = {{From Signals to Knowledge and from Knowledge to Action: Peircean Semiotics and the Grounding of Cognition}},
  shorttitle = {{From Signals to Knowledge and from Knowledge to Action}},
  author = {Camargo, Eduardo and Gudwin, Ricardo},
  year = {2022},
  month = may,
  journal = {Filozofia i Nauka},
  volume = {Zeszyt specjalny},
  number = {10},
  pages = {101--136},
  issn = {2545-1936},
  doi = {10.37240/FiN.2022.10.zs.5},
  abstract = {Cognition is meant as the process of acquiring knowledge from the world. This process is supposed to happen within agents, which build such knowledge with the purpose to use it to determine their actions on the world. Following Peircean ideas, we postulate that such knowledge is encoded by means of signs. According to Peirce, signs are anything that can be used to represent anything else. Also, for Peirce, to represent means to be able to generate another sign, called the interpretant of the original sign, which still holds the same power of interpretability, I.e, its power to be transformed into a new sign, holding this same power. This happens through a process called semiosis, the process by which a sign is transformed into an interpretant. This whole process is performed with the aim of subsidizing the agent in deciding its behavior. So, even though the semiosis process has the power to continue infinitely, it usually stops whenever the generated interpretant brings enough information in order for the agent to effectively act in the world. We take signals to be the substract of signs. Signals are any physical property, which can be measured and captured by the agent, by means of its sensors. This includes any kind of internal memory the agent is able to have access, in order to operate. In this sense, signs can be both in the world (if these signals come from sensors) and within the own agent's mind (if signals come from an internal memory). We understand an agent's mind as the agents' control system. In either case, signals can be abstracted as numbers. Not simply numbers, but numbers coming from specific sensors or specific memories. Using ideas from Peircean philosophy, in this work we postulate a pathway, in which signals, collected by either sensors or memory, can be organized in such a way that they can be effectively used as knowledge, in order for an agent to be able to decide its actions on the world, on the pursuit of its internal motivations. We postulate that agents identify and create a model of the world based on possibilities, existents, and laws, and based on this model, they are able to decide an action that maximizes the chance for the world to gain a shape, which the agents intend for it to be. This theory is postulated particularly for the case of artificial autonomous agents, meant to be constructed by engineering artifacts.},
  langid = {polish},
  keywords = {_tablet,【产品】：MECA、CST,【学科】：AGI,【感觉】：重要,【进度】：准备进行},
  file = {/Users/ethan/LocalFiles/ProgramsFile/Zotero/storage/J5GMVIBG/Camargo_Gudwin_2022_From Signals to Knowledge and from Knowledge to Action - Peircean Semiotics and.pdf}
}

@inproceedings{Camargo.Gudwin_2022_UsingPeirceanSemioticsGroundingCognition,
  title = {Using {{Peircean Semiotics}} as the {{Grounding}} of {{Cognition}}},
  booktitle = {The 2021 {{Summit}} of the {{International Society}} for the {{Study}} of {{Information}}},
  author = {Camargo, Eduardo and Gudwin, Ricardo},
  year = {2022},
  month = apr,
  pages = {135},
  publisher = {{MDPI}},
  doi = {10.3390/proceedings2022081135},
  abstract = {This is a work in progress that aims to study Semiotic Theory as the grounding to support the development of new models of mind. These models can be used to construct artificial intelligent agents to deal with several tasks in the real world. The introduction presents a specific scope of cognition that takes perception and action as two connected moments bound together by signs. Some key concepts related to Peircean categories and sign typology are presented, and they are used to demonstrate their connections to the three instances of the world of ideas: World of Sense, World of Things, and World of Categories. Sensors/Actuators are considered as the unique interface with the properties of the world (signals). They are the basic artificial devices in the process of sign representation that lead semiosis toward more developed signs and, consequently, more complex ideas. Finally, artificial cognition must allow agents to act in the world, and it occurs by means of the sign interpretant, mostly by the energetic interpretant.},
  langid = {english},
  keywords = {【产品】：MECA、CST,【学科】：AGI,【感觉】：重要,【进度】：准备进行},
  file = {/Users/ethan/LocalFiles/ProgramsFile/Zotero/storage/A5I74RQ2/Camargo_Gudwin_2022_Using Peircean Semiotics as the Grounding of Cognition.pdf}
}

@article{Chan_2020_LeniaExpandedUniverse,
  title = {Lenia and {{Expanded Universe}}},
  author = {Chan, Bert Wang-Chak},
  year = {2020},
  journal = {The 2020 Conference on Artificial Life},
  eprint = {2005.03742},
  eprinttype = {arxiv},
  pages = {221--229},
  doi = {10.1162/isal_a_00297},
  abstract = {We report experimental extensions of Lenia, a continuous cellular automata family capable of producing lifelike selforganizing autonomous patterns. The rule of Lenia was generalized into higher dimensions, multiple kernels, and multiple channels. The final architecture approaches what can be seen as a recurrent convolutional neural network. Using semiautomatic search e.g. genetic algorithm, we discovered new phenomena like polyhedral symmetries, individuality, selfreplication, emission, growth by ingestion, and saw the emergence of ``virtual eukaryotes'' that possess internal division of labor and type differentiation. We discuss the results in the contexts of biology, artificial life, and artificial intelligence.},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {【内容】：人工智能,【内容】：人工生命,【内容】：元胞自动机,【感觉】：有趣,【研究】：扩展人工生命,【进度】：未完待续,Computer Science - Artificial Intelligence,Nonlinear Sciences - Cellular Automata and Lattice Gases,Nonlinear Sciences - Pattern Formation and Solitons},
  file = {/Users/ethan/LocalFiles/ProgramsFile/Zotero/storage/4G6PDVQF/Chan_2020_Lenia and Expanded Universe.pdf;/Users/ethan/LocalFiles/ProgramsFile/Zotero/storage/IVRFDUD3/Chan_2020_Lenia and Expanded Universe.md}
}

@misc{Colas.Karch.ea_2022_VygotskianAutotelicArtificialIntelligenceLanguageCultureInternalizationHumanLikeAI,
  title = {Vygotskian {{Autotelic Artificial Intelligence}}: {{Language}} and {{Culture Internalization}} for {{Human-Like AI}}},
  shorttitle = {Vygotskian {{Autotelic Artificial Intelligence}}},
  author = {Colas, C{\'e}dric and Karch, Tristan and {Moulin-Frier}, Cl{\'e}ment and Oudeyer, Pierre-Yves},
  year = {2022},
  month = jun,
  number = {arXiv:2206.01134},
  eprint = {2206.01134},
  eprinttype = {arxiv},
  primaryclass = {cs},
  publisher = {{arXiv}},
  abstract = {Building autonomous artificial agents able to grow open-ended repertoires of skills across their lives is one of the fundamental goals of AI. To that end, a promising developmental approach recommends the design of intrinsically motivated agents that learn new skills by generating and pursuing their own goals \textemdash{} autotelic agents. However, despite recent progress, existing algorithms still show serious limitations in terms of goal diversity, exploration, generalization or skill composition. This perspective calls for the immersion of autotelic agents into rich socio-cultural worlds, an immensely important attribute of our environment that is mostly omitted in modern AI, including deep reinforcement learning research. We focus on language especially, and how its structure and content may support the development of new cognitive functions in artificial agents, just like it does in humans. Indeed, most of our skills could not be learned in isolation. Formal education teaches us to reason systematically, books teach us history, and YouTube might teach us how to cook. Most importantly, our values, traditions, norms and most of our goals are cultural in essence. This knowledge, and some argue, some of our highest cognitive functions such as abstraction, compositional imagination or relational thinking, are formed through linguistic and cultural interactions with others. Inspired by the seminal work of the developmentalist Vygotsky, we suggest the design of Vygotskian autotelic agents able to interact with others and, more importantly, able to internalize these interactions within the agent so as to transform them into cognitive tools supporting the development of new cognitive functions. This perspective paper finds its inspiration in the work of psychologists and philosophers to propose a new AI paradigm in the quest for artificial lifelong skill discovery. It justifies the approach by uncovering several examples of new artificial cognitive functions emerging from interactions between language and embodiment in recent works at the intersection of deep reinforcement learning and natural language processing. Looking forward, it highlights future opportunities and challenges for Vygotskian Autotelic AI research.},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {【学科】：AGI,【学科】：AI,【感觉】：有趣,【感觉】：重要,【进度】：准备进行,Computer Science - Artificial Intelligence,Computer Science - Computation and Language,Computer Science - Machine Learning},
  file = {/Users/ethan/LocalFiles/ProgramsFile/Zotero/storage/3YBT9UFV/Colas_Karch_et-al_2022_Vygotskian Autotelic Artificial Intelligence - Language and Culture.md;/Users/ethan/LocalFiles/ProgramsFile/Zotero/storage/T62SYBL5/Colas_Karch_et-al_2022_Vygotskian Autotelic Artificial Intelligence - Language and Culture.pdf;/Users/ethan/LocalFiles/ProgramsFile/Zotero/storage/XIYZENQG/Colas_Karch_et-al_2022_Vygotskian Autotelic Artificial Intelligence - Language and Culture.docx}
}

@article{dePaula.Gudwin_2015_Evolvingconceptualspacessymbolgroundinglanguagegames,
  title = {Evolving Conceptual Spaces for Symbol Grounding in Language Games},
  author = {{de Paula}, Suelen M. and Gudwin, Ricardo R.},
  year = {2015},
  month = oct,
  journal = {Biologically Inspired Cognitive Architectures},
  volume = {14},
  pages = {73--85},
  issn = {2212683X},
  doi = {10.1016/j.bica.2015.09.006},
  abstract = {A standard approach in the simulation of language evolution is the use of Language Games to model communicative interactions between intelligent agents. Usually, in such language games, an agent uses the results from its perceptual layer to categorise and to conceptualize world objects, a process named categorization. In this paper, we develop an approach to the categorization process, where the decomposition of reality in meaningful experiences is co-evolved with the lexicon formation in the language game. This approach brings some insights on how meaning might be assigned to symbols, in a dynamic and continuously changing environment being experienced by an agent. In order to do that, we use Barsalou's notion of mental simulation and G\textasciidieresis ardenfors' notion of conceptual spaces such that, together with ESOM neural networks, a cognitive architecture can be developed, where mental concepts formation and lexicon formation are able to co-evolve during a language game. The performance of our cognitive architecture is evaluated and the results show that the architecture is able to fulfill its semantics function, by allowing a population of agents to exchange the meaning of linguistic symbols during a naming game, without relying on ``a priori'' categorization scheme provided by an external expert or a set of examples for training a neural network in a previous discrimination game. These results, beyond bringing evidence on potential ways for symbols to get meaning on a biologically realistic way, open a set of possibilities for further uses of conceptual spaces on a much more complex problem: the grounding of a grammatical language.},
  langid = {english},
  keywords = {【产品】：MECA、CST,【学科】：AGI,【感觉】：重要,【进度】：准备进行},
  file = {/Users/ethan/LocalFiles/ProgramsFile/Zotero/storage/8HKLWF84/de Paula_Gudwin_2015_Evolving conceptual spaces for symbol grounding in language games.pdf}
}

@article{Froes.Gudwin_2017_BUILDINGMOTIVATIONALSUBSYSTEMCOGNITIVESYSTEMSTOOLKIT,
  ids = {Froes.Gudwin_2017_BUILDINGMOTIVATIONALSUBSYSTEMCOGNITIVESYSTEMSTOOLKITa},
  title = {{{BUILDING A MOTIVATIONAL SUBSYSTEM FOR THE COGNITIVE SYSTEMS TOOLKIT}}},
  author = {Froes, Eduardo de Moraes and Gudwin, Ricardo Ribeiro},
  year = {2017},
  pages = {7},
  abstract = {Motivations and emotions are intrinsically embedded in animal cognition and behavior, particularly in humans. They are responsible for supporting decision making, stimulating different behaviors such that their internal needs are satisfied. This work proposes the design and implementation of a motivational system endowed with motivational and emotional capacities for the ''Cognitive System Toolkit'' (CST), a software toolkit for cognitive computing being developed by our research group, based on studies from the literature and different implementations of motivational and emotional systems in known cognitive architectures.},
  langid = {english},
  keywords = {【产品】：MECA、CST,【学科】：AGI,【感觉】：重要,【进度】：准备进行,⛔ No DOI found},
  file = {/Users/ethan/LocalFiles/ProgramsFile/Zotero/storage/SX7LRNW2/Froes_Gudwin_2017_BUILDING A MOTIVATIONAL SUBSYSTEM FOR THE COGNITIVE SYSTEMS TOOLKIT.pdf}
}

@inproceedings{Grassiotto.Colombini.ea_2022_CogToMCSTimplementationTheoryMindCognitiveSystemsToolkit,
  title = {{{CogToM-CST}}: {{An}} Implementation of the {{Theory}} of {{Mind}} for the {{Cognitive Systems Toolkit}}:},
  shorttitle = {{{CogToM-CST}}},
  booktitle = {Proceedings of the 14th {{International Conference}} on {{Agents}} and {{Artificial Intelligence}}},
  author = {Grassiotto, Fabio and Colombini, Esther and Sim{\~o}es, Alexandre and Gudwin, Ricardo and Costa, Paula},
  year = {2022},
  pages = {462--469},
  publisher = {{SCITEPRESS - Science and Technology Publications}},
  address = {{Online Streaming, --- Select a Country ---}},
  doi = {10.5220/0010836300003116},
  isbn = {978-989-758-547-0},
  langid = {english},
  keywords = {_tablet_modified,【产品】：MECA、CST,【学科】：AGI,【感觉】：重要,【进度】：准备进行},
  file = {/Users/ethan/LocalFiles/ProgramsFile/Zotero/storage/QR8WY75Z/Grassiotto et al_2022_CogToM-CST - An implementation of the Theory of Mind for the Cognitive Systems.pdf}
}

@misc{Graves.Wayne.ea_2014_NeuralTuringMachines,
  title = {Neural {{Turing Machines}}},
  author = {Graves, Alex and Wayne, Greg and Danihelka, Ivo},
  year = {2014},
  month = dec,
  number = {arXiv:1410.5401},
  eprint = {1410.5401},
  eprinttype = {arxiv},
  primaryclass = {cs},
  publisher = {{arXiv}},
  abstract = {We extend the capabilities of neural networks by coupling them to external memory resources, which they can interact with by attentional processes. The combined system is analogous to a Turing Machine or Von Neumann architecture but is differentiable end-toend, allowing it to be efficiently trained with gradient descent. Preliminary results demonstrate that Neural Turing Machines can infer simple algorithms such as copying, sorting, and associative recall from input and output examples.},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {【内容】：图灵机,【内容】：神经网络,【内容】：神经网络图灵机,【学科】：AI,【学科】：计算机科学,【感觉】：有趣,【进度】：未完待续,Computer Science - Neural and Evolutionary Computing},
  file = {/Users/ethan/LocalFiles/ReferencesFile/Zotero/storage/2CN9D3DP/Graves_Wayne_et-al_2014_Neural Turing Machines.pdf;/Users/ethan/LocalFiles/ReferencesFile/Zotero/storage/94MC3PFV/Graves_Wayne_et-al_2014_Neural Turing Machines.zip;/Users/ethan/LocalFiles/ReferencesFile/Zotero/storage/APVKXAEJ/Graves_Wayne_et-al_2014_Neural Turing Machines.md}
}

@article{Gudwin.Paraense.ea_2017_MultipurposeEnhancedCognitiveArchitectureMECA,
  title = {The {{Multipurpose Enhanced Cognitive Architecture}} ({{MECA}})},
  author = {Gudwin, Ricardo and Paraense, Andr{\'e} and {de Paula}, Suelen M. and Fr{\'o}es, Eduardo and Gibaut, Wandemberg and Castro, Elisa and Figueiredo, Vera and Raizer, Klaus},
  year = {2017},
  month = oct,
  journal = {Biologically Inspired Cognitive Architectures},
  volume = {22},
  pages = {20--34},
  issn = {2212683X},
  doi = {10.1016/j.bica.2017.09.006},
  abstract = {In this paper, we present an introduction to MECA, the Multipurpose Enhanced Cognitive Architecture, a cognitive architecture developed by our research group and implemented in the Java language. MECA was designed based on many ideas coming from Dual Process Theory, Dynamic Subsumption, Conceptual Spaces and Grounded Cognition, and constructed using CST, a toolkit for the construction of cognitive architectures in Java, also developed by our group. Basically MECA promotes an hybridism of SOAR, used to implement rule-based processing and space-state exploration in System 2 modules, with a Dynamic Subsumption Motivational System performing the role of System 1, using a representational system based on conceptual spaces and grounded cognition. We review the conceptual background used on MECA and further provide a detailed description of the many MECA sub-systems.},
  langid = {english},
  keywords = {【产品】：MECA、CST,【学科】：AGI,【感觉】：重要,【进度】：准备进行},
  file = {/Users/ethan/LocalFiles/ProgramsFile/Zotero/storage/Q8JA5I6V/Gudwin_Paraense_et-al_2017_The Multipurpose Enhanced Cognitive Architecture (MECA).pdf}
}

@article{Gudwin.Paraense.ea_2018_OverviewMultipurposeEnhancedCognitiveArchitectureMECA,
  title = {An {{Overview}} of the {{Multipurpose Enhanced Cognitive Architecture}} ({{MECA}})},
  author = {Gudwin, Ricardo and Paraense, Andr{\'e} and {de Paula}, Suelen and Fr{\'o}es, Eduardo and Gibaut, Wandemberg and Castro, Elisa and Figueiredo, Vera and Raizer, Klaus},
  year = {2018},
  journal = {Procedia Computer Science},
  volume = {123},
  pages = {155--160},
  issn = {18770509},
  doi = {10.1016/j.procs.2018.01.025},
  langid = {english},
  keywords = {【学科】：AGI,【感觉】：有趣,【感觉】：重要,【进度】：准备进行},
  file = {/Users/ethan/LocalFiles/ProgramsFile/Zotero/storage/9PNGLG5S/Gudwin_Paraense_et-al_2018_An Overview of the Multipurpose Enhanced Cognitive Architecture (MECA).pdf;/Users/ethan/LocalFiles/ProgramsFile/Zotero/storage/FTITGCLT/Gudwin_Paraense_et-al_2018_An Overview of the Multipurpose Enhanced Cognitive Architecture (MECA).docx}
}

@article{Gudwin.Paraense.ea_2018_urbantrafficcontrollerusingMECAcognitivearchitecture,
  title = {An Urban Traffic Controller Using the {{MECA}} Cognitive Architecture},
  author = {Gudwin, Ricardo and Paraense, Andr{\'e} and {de Paula}, Suelen M. and Fr{\'o}es, Eduardo and Gibaut, Wandemberg and Castro, Elisa and Figueiredo, Vera and Raizer, Klaus},
  year = {2018},
  month = oct,
  journal = {Biologically Inspired Cognitive Architectures},
  volume = {26},
  pages = {41--54},
  issn = {2212683X},
  doi = {10.1016/j.bica.2018.07.015},
  abstract = {In this paper, we present a Cognitive Manager for urban traffic control, built using MECA, the Multipurpose Enhanced Cognitive Architecture, a cognitive architecture developed by our research group and implemented in the Java language. The Cognitive Manager controls a set of traffic lights in a junction of roads based on information collected from sensors installed on the many lanes feeding the junction. We tested our Junction Manager in 4 different test topologies using the SUMO traffic simulator, and with different traffic loads. The junction manager seeks to optimize the average waiting times for all the cars crossing the junction, while at the same time being able to provide preference to special cars (police cars or firefighters), called Smart Cars, and equipped with special devices that grant them special treatment during the phase allocation policies provided by the architecture. Simulation results provide evidence for an enhanced behavior while compared to fixed-time policies.},
  langid = {english},
  keywords = {【产品】：MECA、CST,【学科】：AGI,【感觉】：重要,【进度】：准备进行},
  file = {/Users/ethan/LocalFiles/ProgramsFile/Zotero/storage/T6B7RPM3/Gudwin_Paraense_et-al_2018_An urban traffic controller using the MECA cognitive architecture.pdf}
}

@misc{Hudson.Manning_2019_LearningAbstractionNeuralStateMachine,
  title = {Learning by {{Abstraction}}: {{The Neural State Machine}}},
  shorttitle = {Learning by {{Abstraction}}},
  author = {Hudson, Drew A. and Manning, Christopher D.},
  year = {2019},
  month = nov,
  number = {arXiv:1907.03950},
  eprint = {1907.03950},
  eprinttype = {arxiv},
  primaryclass = {cs},
  publisher = {{arXiv}},
  abstract = {We introduce the Neural State Machine, seeking to bridge the gap between the neural and symbolic views of AI and integrate their complementary strengths for the task of visual reasoning. Given an image, we first predict a probabilistic graph that represents its underlying semantics and serves as a structured world model. Then, we perform sequential reasoning over the graph, iteratively traversing its nodes to answer a given question or draw a new inference. In contrast to most neural architectures that are designed to closely interact with the raw sensory data, our model operates instead in an abstract latent space, by transforming both the visual and linguistic modalities into semantic concept-based representations, thereby achieving enhanced transparency and modularity. We evaluate our model on VQA-CP and GQA, two recent VQA datasets that involve compositionality, multi-step inference and diverse reasoning skills, achieving state-of-the-art results in both cases. We provide further experiments that illustrate the model's strong generalization capacity across multiple dimensions, including novel compositions of concepts, changes in the answer distribution, and unseen linguistic structures, demonstrating the qualities and efficacy of our approach.},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {【内容】：神经网络,【内容】：神经网络状态机,【内容】：计算机视觉,【学科】：AI,【学科】：计算机科学,【感觉】：有趣,【进度】：准备进行,Computer Science - Artificial Intelligence,Computer Science - Computation and Language,Computer Science - Computer Vision and Pattern Recognition,Computer Science - Machine Learning},
  file = {/Users/ethan/LocalFiles/ProgramsFile/Zotero/storage/F39A8S6W/Hudson_Manning_2019_Learning by Abstraction - The Neural State Machine.md;/Users/ethan/LocalFiles/ProgramsFile/Zotero/storage/KKKAYTLX/Hudson_Manning_2019_Learning by Abstraction - The Neural State Machine.pdf}
}

@article{Kazanovich.Kazanovich_2018_HowAnimalsFindTheirWaySpaceExperimentsModeling,
  title = {How {{Animals Find Their Way}} in {{Space}}. {{Experiments}} and {{Modeling}}},
  author = {{\cyrchar\CYRK}{\cyrchar\cyra}{\cyrchar\cyrz}{\cyrchar\cyra}{\cyrchar\cyrn}{\cyrchar\cyro}{\cyrchar\cyrv}{\cyrchar\cyri}{\cyrchar\cyrch}, {\cyrchar\CYRYA}.{\cyrchar\CYRB} and Kazanovich, Yakov},
  year = {2018},
  month = nov,
  journal = {\cyrchar\CYRM\cyrchar\cyra\cyrchar\cyrt\cyrchar\cyre\cyrchar\cyrm\cyrchar\cyra\cyrchar\cyrt\cyrchar\cyri\cyrchar\cyrch\cyrchar\cyre\cyrchar\cyrs\cyrchar\cyrk\cyrchar\cyra\cyrchar\cyrya{} \cyrchar\cyrb\cyrchar\cyri\cyrchar\cyro\cyrchar\cyrl\cyrchar\cyro\cyrchar\cyrg\cyrchar\cyri\cyrchar\cyrya{} \cyrchar\cyri{} \cyrchar\cyrb\cyrchar\cyri\cyrchar\cyro\cyrchar\cyri\cyrchar\cyrn\cyrchar\cyrf\cyrchar\cyro\cyrchar\cyrr\cyrchar\cyrm\cyrchar\cyra\cyrchar\cyrt\cyrchar\cyri\cyrchar\cyrk\cyrchar\cyra},
  volume = {13},
  pages = {t132-t161},
  doi = {10.17537/2018.13.t132},
  keywords = {【内容】：神经元连接规律,【内容】：空间感知,【学科】：生命科学,【学科】：认知科学},
  file = {/Users/ethan/LocalFiles/ProgramsFile/Zotero/storage/AQRMWN2T/Kazanovich_MysinMathBiolBioinf-18.pdf;/Users/ethan/LocalFiles/ProgramsFile/Zotero/storage/PG37MZ45/Казанович_Kazanovich_2018_How Animals Find Their Way in Space. Experiments and Modeling.pdf}
}

@article{Letelier.Marin.ea_2003_AutopoieticMRsystems,
  title = {Autopoietic and ({{M}},{{R}}) Systems},
  author = {Letelier, Juan Carlos and Mar{\'{\i}}n, Gonzalo and Mpodozis, Jorge},
  year = {2003},
  month = may,
  journal = {Journal of Theoretical Biology},
  volume = {222},
  number = {2},
  pages = {261--272},
  issn = {00225193},
  doi = {10.1016/S0022-5193(03)00034-1},
  abstract = {From the many attempts to produce a conceptual framework for the organization of living systems, the notions of (M,R) systems and Autopoiesis stand out for their rigor, their presupposition of the circularity of metabolism, and the new epistemologies that they imply. From their inceptions, these two notions have been essentially disconnected because each has defined its own language and tools. Here we demonstrate the existence of a deep conceptual link between (M,R) systems and Autopoietic systems. This relationship permits us to posit that Autopoietic systems, which have been advanced as capturing the central aspects of living systems, are a subset of (M,R) systems. This result, in conjunction with previous theorems proved by Rosen, can be used to outline a demonstration that the operation of Autopoietic systems cannot be simulated by Turing machines. This powerful result shows the potential of linking these two models. Finally, we suggest that the formalism of (M,R) systems could be used to model the circularity of metabolism.},
  langid = {english},
  keywords = {【内容】：因果涌现,【学科】：复杂系统,【项目】：因果涌现读书会},
  file = {/Users/ethan/LocalFiles/ProgramsFile/Zotero/storage/MS2B2873/Letelier_Marı́n_et-al_2003_Autopoietic and (M,R) systems.pdf;/Users/ethan/LocalFiles/ProgramsFile/Zotero/storage/TA27HHCF/Letelier_Marı́n_et-al_2003_Autopoietic and (M,R) systems.md}
}

@misc{Liang_2022_BrainishFormalizingMultimodalLanguageIntelligenceConsciousness,
  title = {Brainish: {{Formalizing A Multimodal Language}} for {{Intelligence}} and {{Consciousness}}},
  shorttitle = {Brainish},
  author = {Liang, Paul Pu},
  year = {2022},
  month = may,
  number = {arXiv:2205.00001},
  eprint = {2205.00001},
  eprinttype = {arxiv},
  primaryclass = {cs},
  publisher = {{arXiv}},
  abstract = {Having a rich multimodal inner language is an important component of human intelligence that enables several necessary core cognitive functions such as multimodal prediction, translation, and generation. Building upon the Conscious Turing Machine (CTM), a machine model for consciousness proposed by Blum and Blum [13], we describe the desiderata of a multimodal language called BRAINISH, comprising words, images, audio, and sensations combined in representations that the CTM's processors use to communicate with each other. We define the syntax and semantics of BRAINISH before operationalizing this language through the lens of multimodal artificial intelligence, a vibrant research area studying the computational tools necessary for processing and relating information from heterogeneous signals. Our general framework for learning BRAINISH involves designing (1) unimodal encoders to segment and represent unimodal data, (2) a coordinated representation space that relates and composes unimodal features to derive holistic meaning across multimodal inputs, and (3) decoders to map multimodal representations into predictions (for fusion) or raw data (for translation or generation). Through discussing how BRAINISH is crucial for communication and coordination in order to achieve consciousness in the CTM, and by implementing a simple version of BRAINISH and evaluating its capability of demonstrating intelligence on multimodal prediction and retrieval tasks on several real-world image, text, and audio datasets, we argue that such an inner language will be important for advances in machine models of intelligence and consciousness.},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {【学科】：AGI,【学科】：AI,【感觉】：有趣,【感觉】：重要,【进度】：准备进行,Computer Science - Artificial Intelligence,Computer Science - Computation and Language,Computer Science - Machine Learning},
  file = {/Users/ethan/LocalFiles/ProgramsFile/Zotero/storage/7RTKRTNK/Liang_2022_Brainish - Formalizing A Multimodal Language for Intelligence and Consciousness.md;/Users/ethan/LocalFiles/ProgramsFile/Zotero/storage/AG3RZNX3/Liang_2022_Brainish - Formalizing A Multimodal Language for Intelligence and Consciousness.pdf;/Users/ethan/LocalFiles/ProgramsFile/Zotero/storage/UWGX82RH/Liang_2022_Brainish - Formalizing A Multimodal Language for Intelligence and Consciousness.docx}
}

@article{Lindes_2022_ConstructingMeaningPiecePieceComputationalCognitiveModelHumanSentenceComprehension,
  title = {Constructing {{Meaning}}, {{Piece}} by {{Piece}}: {{A Computational Cognitive Model}} of {{Human Sentence Comprehension}}},
  author = {Lindes, Peter},
  year = {2022},
  pages = {289},
  abstract = {具有机器人语言的人工智能系统不会尝试对人类处理进行建模。人类语言处理的心理语言模型没有可操作的计算模型。为了解决这些问题，本论文有助于在回答两个相互关联的科学问题方面取得进展：人类思维如何进行句子理解，以及我们如何使人工代理使用自然语言与人类协作。我们使用一个名为 Lucia 的系统来做到这一点，这是一个人类句子理解的计算认知模型，它通过逐段构建句子的含义来工作。 Lucia 模型是根据人类语言理解的五个最重要的定性原则设计的。为了证明它的结果是有用的，它确实在一个名为 Rosie 的人工代理中体现了端到端的理解 (E3C)。为了模拟人类理解的关键特征，它利用认知语言学、心理语言学、人工智能和机器人学的研究来：表示语言形式含义的可组合知识 (CKM)，进行增量即时解释处理 (I3P)，并进行它使用一般认知机制（GCM）。该模型导致了从经验中获得语言的理论（LAE），其中一些部分已经通过实验实现。 为了符合这些原则，Lucia 模型在一个名为 Rosie 的机器人代理中实现，以进行 E3C。它使用体现构造语法 (ECG) 作为其表示可组合意义知识 (CKM) 的方法，并证明可以使用依赖于通用认知机制 (GCM) 的新型理解算法来增量处理 (I3P) 这种知识。飙升认知架构以产生具体的端到端理解 (E3C)。Lucia 为回答更广泛的科学问题做出了多项贡献。它为基于三阶段构建周期的增量处理（I3P）提供了一种新颖的理论。它提供了一个关于记忆在理解过程中如何相互作用的理论。它展示了对具体机器人代理的扎实理解。最后，它提供了一个详细的、功能性的认知 E3C 处理模型，可以作为进一步研究大脑中人类语言处理建模和为人工代理设计更大规模语言模型的基础。},
  langid = {english},
  keywords = {_tablet,【产品】：SOAR,【内容】：构式语法,【内容】：语义理解,【内容】：通用人工智能,【内容】：逻辑推理,【学科】：AGI,【感觉】：有趣,【感觉】：重要,【进度】：准备进行,⛔ No DOI found},
  file = {/Users/ethan/LocalFiles/ProgramsFile/Zotero/storage/W2ZGRY3W/Lindes_2022_Constructing Meaning, Piece by Piece - A Computational Cognitive Model of Human.md;/Users/ethan/LocalFiles/ProgramsFile/Zotero/storage/WGEPFD7G/Lindes_2022_Constructing Meaning, Piece by Piece - A Computational Cognitive Model of Human.pdf}
}

@article{Mayner.Marshall.ea_2018_PyPhitoolboxintegratedinformationtheory,
  ids = {Mayner.Marshall.ea_2018},
  title = {{{PyPhi}}: {{A}} Toolbox for Integrated Information Theory},
  shorttitle = {{{PyPhi}}},
  author = {Mayner, William G. P. and Marshall, William and Albantakis, Larissa and Findlay, Graham and Marchman, Robert and Tononi, Giulio},
  editor = {Blackwell, Kim T.},
  year = {2018},
  month = jul,
  journal = {PLOS Computational Biology},
  volume = {14},
  number = {7},
  pages = {e1006343},
  issn = {1553-7358},
  doi = {10/gdxwmx},
  abstract = {Integrated information theory provides a mathematical framework to fully characterize the cause-effect structure of a physical system. Here, we introduce PyPhi, a Python software package that implements this framework for causal analysis and unfolds the full cause-effect structure of discrete dynamical systems of binary elements. The software allows users to easily study these structures, serves as an up-to-date reference implementation of the formalisms of integrated information theory, and has been applied in research on complexity, emergence, and certain biological questions. We first provide an overview of the main algorithm and demonstrate PyPhi's functionality in the course of analyzing an example system, and then describe details of the algorithm's design and implementation. PyPhi can be installed with Python's package manager via the command `pip install pyphi' on Linux and macOS systems equipped with Python 3.4 or higher. PyPhi is open-source and licensed under the GPLv3; the source code is hosted on GitHub at https://github.com/ wmayner/pyphi. Comprehensive and continually-updated documentation is available at https://pyphi.readthedocs.io. The pyphi-users mailing list can be joined at https://groups. google.com/forum/\#!forum/pyphi-users. A web-based graphical interface to the software is available at http://integratedinformationtheory.org/calculate.html.},
  langid = {english},
  keywords = {【内容】：工具包,【内容】：整合信息论,【学科】：信息论,【学科】：认知科学,【感觉】：有趣,【感觉】：重要,【进度】：准备进行},
  file = {/Users/ethan/LocalFiles/ProgramsFile/Zotero/storage/EJCV66ML/Mayner_Marshall_et-al_2018_PyPhi - A toolbox for integrated information theory.pdf}
}

@article{Oizumi.Albantakis.ea_2014_PhenomenologyMechanismsConsciousnessIntegratedInformationTheory30,
  title = {From the {{Phenomenology}} to the {{Mechanisms}} of {{Consciousness}}: {{Integrated Information Theory}} 3.0},
  shorttitle = {From the {{Phenomenology}} to the {{Mechanisms}} of {{Consciousness}}},
  author = {Oizumi, Masafumi and Albantakis, Larissa and Tononi, Giulio},
  editor = {Sporns, Olaf},
  year = {2014},
  month = may,
  journal = {PLoS Computational Biology},
  volume = {10},
  number = {5},
  pages = {e1003588},
  issn = {1553-7358},
  doi = {10/sqz},
  abstract = {This paper presents Integrated Information Theory (IIT) of consciousness 3.0, which incorporates several advances over previous formulations. IIT starts from phenomenological axioms: information says that each experience is specific \textendash{} it is what it is by how it differs from alternative experiences; integration says that it is unified \textendash{} irreducible to noninterdependent components; exclusion says that it has unique borders and a particular spatio-temporal grain. These axioms are formalized into postulates that prescribe how physical mechanisms, such as neurons or logic gates, must be configured to generate experience (phenomenology). The postulates are used to define intrinsic information as ``differences that make a difference'' within a system, and integrated information as information specified by a whole that cannot be reduced to that specified by its parts. By applying the postulates both at the level of individual mechanisms and at the level of systems of mechanisms, IIT arrives at an identity: an experience is a maximally irreducible conceptual structure (MICS, a constellation of concepts in qualia space), and the set of elements that generates it constitutes a complex. According to IIT, a MICS specifies the quality of an experience and integrated information WMax its quantity. From the theory follow several results, including: a system of mechanisms may condense into a major complex and non-overlapping minor complexes; the concepts that specify the quality of an experience are always about the complex itself and relate only indirectly to the external environment; anatomical connectivity influences complexes and associated MICS; a complex can generate a MICS even if its elements are inactive; simple systems can be minimally conscious; complicated systems can be unconscious; there can be true ``zombies'' \textendash{} unconscious feed-forward systems that are functionally equivalent to conscious complexes.},
  langid = {english},
  keywords = {_tablet,【内容】：整合信息论,【学科】：认知科学,【来源】：集智学园,【进度】：准备进行},
  file = {/Users/ethan/LocalFiles/ProgramsFile/Zotero/storage/H6TD35HN/Oizumi_Albantakis_et-al_2014_From the Phenomenology to the Mechanisms of Consciousness - Integrated(演示文稿).pdf;/Users/ethan/LocalFiles/ProgramsFile/Zotero/storage/HFFFR7TZ/Oizumi_Albantakis_et-al_2014_From the Phenomenology to the Mechanisms of Consciousness - Integrated(机器翻译).docx;/Users/ethan/LocalFiles/ProgramsFile/Zotero/storage/W4S2Z6RX/Oizumi et al_2014_From the Phenomenology to the Mechanisms of Consciousness - Integrated.pdf}
}

@article{OKeefe_1976_Placeunitshippocampusfreelymovingrat,
  title = {Place Units in the Hippocampus of the Freely Moving Rat},
  author = {O'Keefe, John},
  year = {1976},
  month = jan,
  journal = {Experimental Neurology},
  volume = {51},
  number = {1},
  pages = {78--109},
  issn = {0014-4886},
  doi = {10.1016/0014-4886(76)90055-8},
  abstract = {Single units were recorded from the CA1 field of the hippocampus in the freely-moving rat. They were classified as place units, displace units or others. Place units were defined as those for which the rat's position on the maze was a necessary condition for maximal unit firing. Some of these place units (misplace units) fired maximally when the animal sniffed in a place, either because it found something new there or failed to find something which was usually there. Displace units increased their rates during behaviors associated with theta activity in the hippocampal slow waves. In general these were behaviors which changed the rat's position relative to the environment. The influence of various environmental manipulations (e.g., turning off the room lights) on the firing pattern of the place units was tested and the results suggest that they were not responding to a simple sensory stimulus nor to a specific motor behavior. Nor could the unit firing be due purely to motivational or incentive factors. The results are interpreted as strong support for the cognitive map theory of hippocampal function.},
  langid = {english},
  keywords = {【内容】：神经元连接规律,【内容】：空间感知,【学科】：生命科学,【学科】：认知科学},
  file = {/Users/ethan/LocalFiles/ProgramsFile/Zotero/storage/FPV5NNEI/0014488676900558.html}
}

@article{OKeefe.Dostrovsky_1971_hippocampusspatialmapPreliminaryevidenceunitactivityfreelymovingrat,
  title = {The Hippocampus as a Spatial Map. {{Preliminary}} Evidence from Unit Activity in the Freely-Moving Rat},
  author = {O'Keefe, J. and Dostrovsky, J.},
  year = {1971},
  month = nov,
  journal = {Brain Research},
  volume = {34},
  number = {1},
  pages = {171--175},
  issn = {0006-8993},
  doi = {10.1016/0006-8993(71)90358-1},
  langid = {english},
  pmid = {5124915},
  keywords = {【内容】：神经元连接规律,【内容】：空间感知,【学科】：生命科学,【学科】：认知科学,Acoustics,Animals,Arousal,Behavior; Animal,Cognition,Cues,Electrodes; Implanted,Electrophysiology,Feeding Behavior,Grooming,Hearing,Hippocampus,Homing Behavior,Light,Limbic System,Locomotion,Motor Activity,Neurons,Odorants,Orientation,Rats,Sleep,Smell,Touch,Vision; Ocular}
}

@misc{Reser_2022_ComputationalArchitectureMachineConsciousnessArtificialSuperintelligenceUpdatingWorkingMemoryIteratively,
  title = {A {{Computational Architecture}} for {{Machine Consciousness}} and {{Artificial Superintelligence}}: {{Updating Working Memory Iteratively}}},
  author = {Reser, Jared Edward},
  year = {2022},
  month = may,
  abstract = {This theoretical article examines how to construct human-like working memory and thought processes within a computer. There should be two working memory stores, one analogous to sustained firing in association cortex, and one analogous to synaptic potentiation in the cerebral cortex. These stores must be constantly updated with new representations that arise from either environmental stimulation or internal processing. They should be updated continuously, and in an iterative fashion, meaning that, in the next state, some items in the set of coactive items should always be retained. Thus, the set of concepts coactive in working memory will evolve gradually and incrementally over time. This makes each state is a revised iteration of the preceding state and causes successive states to overlap and blend with respect to the set of representations they contain. As new representations are added and old ones are subtracted, some remain active for several seconds over the course of these changes. This persistent activity, similar to that used in artificial recurrent neural networks, is used to spread activation energy throughout the global workspace to search for the next associative update. The result is a chain of associatively linked intermediate states that are capable of advancing toward a solution or goal. Iterative updating is conceptualized here as an information processing strategy, a computational and neurophysiological determinant of the stream of thought, and an algorithm for designing and programming artificial intelligence.},
  keywords = {【学科】：AI,【感觉】：有趣,【感觉】：重要,【进度】：准备进行},
  file = {/Users/ethan/LocalFiles/ProgramsFile/Zotero/storage/MM6LT3CL/Reser_2022_A Computational Architecture for Machine Consciousness and Artificial.md;/Users/ethan/LocalFiles/ProgramsFile/Zotero/storage/N8E72C8N/Reser_2022_A Computational Architecture for Machine Consciousness and Artificial.docx;/Users/ethan/LocalFiles/ProgramsFile/Zotero/storage/NQU72SF8/Signorelli_Wang_et-al_2021_A Compositional Model of Consciousness Based on Consciousness-Only.pdf}
}

@article{Signorelli.Wang.ea_2021_CompositionalModelConsciousnessBasedConsciousnessOnly,
  title = {A {{Compositional Model}} of {{Consciousness Based}} on {{Consciousness-Only}}},
  author = {Signorelli, Camilo Miguel and Wang, Quanlong and Khan, Ilyas},
  year = {2021},
  month = mar,
  journal = {Entropy},
  volume = {23},
  number = {3},
  pages = {308},
  issn = {1099-4300},
  doi = {10.3390/e23030308},
  abstract = {Scientific studies of consciousness rely on objects whose existence is assumed to be independent of any consciousness. On the contrary, we assume consciousness to be fundamental, and that one of the main features of consciousness is characterized as being other-dependent. We set up a framework which naturally subsumes this feature by defining a compact closed category where morphisms represent conscious processes. These morphisms are a composition of a set of generators, each being specified by their relations with other generators, and therefore co-dependent. The framework is general enough and fits well into a compositional model of consciousness. Interestingly, we also show how our proposal may become a step towards avoiding the hard problem of consciousness, and thereby address the combination problem of conscious experiences.},
  langid = {english},
  keywords = {【学科】：意识理论,【感觉】：有趣,【方法】：范畴论,【进度】：准备进行},
  file = {/Users/ethan/LocalFiles/ProgramsFile/Zotero/storage/SM5BIYBT/Signorelli_Wang_et-al_2021_A Compositional Model of Consciousness Based on Consciousness-Only(机器翻译).docx;/Users/ethan/LocalFiles/ProgramsFile/Zotero/storage/VRHCV6WI/Signorelli_Wang_et-al_2021_A Compositional Model of Consciousness Based on Consciousness-Only.pdf}
}

@article{Signorelli.Wang.ea_2021_Reasoningconsciousexperienceaxiomaticgraphicalmathematics,
  title = {Reasoning about Conscious Experience with Axiomatic and Graphical Mathematics},
  author = {Signorelli, Camilo Miguel and Wang, Quanlong and Coecke, Bob},
  year = {2021},
  month = oct,
  journal = {Consciousness and Cognition},
  volume = {95},
  pages = {103168},
  issn = {10538100},
  doi = {10.1016/j.concog.2021.103168},
  abstract = {We cast aspects of consciousness in axiomatic mathematical terms, using the graphical calculus of general process theories (a.k.a symmetric monoidal categories and Frobenius algebras therein). This calculus exploits the ontological neutrality of process theories. A toy example using the axiomatic calculus is given to show the power of this approach, recovering other aspects of conscious experience, such as external and internal subjective distinction, privacy or unread\- ability of personal subjective experience, and phenomenal unity, one of the main issues for sci\- entific studies of consciousness. In fact, these features naturally arise from the compositional nature of axiomatic calculus.},
  langid = {english},
  keywords = {【学科】：意识理论,【感觉】：有趣,【方法】：范畴论,【进度】：准备进行},
  file = {/Users/ethan/LocalFiles/ProgramsFile/Zotero/storage/CXUN5PQB/Signorelli_Wang_et-al_2021_Reasoning about conscious experience with axiomatic and graphical mathematics.pdf;/Users/ethan/LocalFiles/ProgramsFile/Zotero/storage/T4ZKWIY5/Signorelli_Wang_et-al_2021_Reasoning about conscious experience with axiomatic and graphical mathematics(机器翻译).docx}
}

@article{Tononi:2015,
  title = {Integrated Information Theory},
  author = {Tononi, G.},
  year = {2015},
  journal = {Scholarpedia},
  volume = {10},
  number = {1},
  pages = {4164},
  doi = {10/gfwjq5},
  keywords = {【内容】：整合信息论,【学科】：认知科学},
  file = {/Users/ethan/LocalFiles/ProgramsFile/Zotero/storage/XZ5GJDSI/Tononi_2015_Integrated information theory.webarchive}
}

@article{Tononi.Boly.ea_2016_Integratedinformationtheoryconsciousnessitsphysicalsubstrate,
  ids = {Tononi.Boly.ea_2016},
  title = {Integrated Information Theory: From Consciousness to Its Physical Substrate},
  shorttitle = {Integrated Information Theory},
  author = {Tononi, Giulio and Boly, Melanie and Massimini, Marcello and Koch, Christof},
  year = {2016},
  month = jul,
  journal = {Nature Reviews Neuroscience},
  volume = {17},
  number = {7},
  pages = {450--461},
  issn = {1471-003X, 1471-0048},
  doi = {10/f8rbxc},
  abstract = {In this Opinion article, we discuss how integrated information theory accounts for several aspects of the relationship between consciousness and the brain. Integrated information theory starts from the essential properties of phenomenal experience, from which it derives the requirements for the physical substrate of consciousness. It argues that the physical substrate of consciousness must be a maximum of intrinsic cause\textendash effect power and provides a means to determine, in principle, the quality and quantity of experience. The theory leads to some counterintuitive predictions and can be used to develop new tools for assessing consciousness in non-communicative patients.},
  langid = {english},
  keywords = {【内容】：因果涌现,【内容】：整合信息论,【学科】：复杂系统,【学科】：认知科学,【来源】：集智学园,【进度】：准备进行,【项目】：因果涌现读书会},
  file = {/Users/ethan/LocalFiles/ProgramsFile/Zotero/storage/JW4DP2PZ/Tononi_Boly_et-al_2016_Integrated information theory - from consciousness to its physical substrate(机器翻译).docx;/Users/ethan/LocalFiles/ProgramsFile/Zotero/storage/NTGSLQQI/Tononi_Boly_et-al_2016_Integrated information theory - from consciousness to its physical substrate(演示文稿).pdf;/Users/ethan/LocalFiles/ProgramsFile/Zotero/storage/VB7SRCTJ/Tononi_Boly_et-al_2016_Integrated information theory - from consciousness to its physical substrate.pdf}
}

@article{williams2010nonnegative,
  title = {Nonnegative Decomposition of Multivariate Information},
  author = {Williams, Paul L. and Beer, Randall D.},
  year = {2010},
  eprint = {1004.2515},
  eprinttype = {arxiv},
  primaryclass = {cs.IT},
  archiveprefix = {arXiv},
  keywords = {_tablet,【内容】：互信息,【内容】：因果涌现,【内容】：降维,【学科】：信息论,【学科】：复杂系统,【进度】：准备进行,【项目】：因果涌现读书会},
  file = {/Users/ethan/LocalFiles/ProgramsFile/Zotero/storage/BDBT8TWH/Williams_Beer_2010_Nonnegative decomposition of multivariate information.pdf;/Users/ethan/LocalFiles/ProgramsFile/Zotero/storage/GBKZQLYW/Williams_Beer_2010_Nonnegative decomposition of multivariate information.md}
}


